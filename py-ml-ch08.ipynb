{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Machine Learning to Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyprind\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "reload_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:56\n"
     ]
    }
   ],
   "source": [
    "if reload_data:\n",
    "    pbar = pyprind.ProgBar(50000)\n",
    "    labels = {'pos':1, 'neg':0}\n",
    "    df = pd.DataFrame()\n",
    "    for s in ('test', 'train'):\n",
    "        for l in ('pos', 'neg'):\n",
    "            path ='./downloads/aclImdb/%s/%s' % (s, l)\n",
    "            for file in os.listdir(path):\n",
    "                with open(os.path.join(path, file), 'r', encoding=\"utf8\") as infile:\n",
    "                    txt = infile.read()\n",
    "                df = df.append([[txt, labels[l]]], ignore_index=True)\n",
    "                pbar.update()\n",
    "\n",
    "    df.columns = ['review', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if reload_data:\n",
    "    df.to_csv('./downloads/aclImdb/movie_data.csv', index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n",
      "0  Gorgeous Annie Belle in her prime stars in thi...          1\n",
      "1  How is bear´s paw, elephant´s trunk or monkey´...          1\n",
      "2  The Regard of Flight, written and performed by...          1\n",
      "3  Based on an actual story, John Boorman shows t...          1\n",
      "4  To solve a challenging problem, you need to st...          1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./downloads/aclImdb/movie_data.csv', encoding='utf8')\n",
    "print(df.head())\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "df = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer()\n",
    "docs = np.array(['The sun is shining', 'The water is sweet', 'The sun is shining and the water is sweet'])\n",
    "bag = count.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sun': 3, 'is': 1, 'water': 6, 'shining': 2, 'the': 5, 'sweet': 4, 'and': 0}\n"
     ]
    }
   ],
   "source": [
    "print(count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 0 1 0]\n",
      " [0 1 0 0 1 1 1]\n",
      " [1 2 1 1 1 2 1]]\n"
     ]
    }
   ],
   "source": [
    "print(bag.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.43370786  0.55847784  0.55847784  0.          0.43370786\n",
      "   0.        ]\n",
      " [ 0.          0.43370786  0.          0.          0.55847784  0.43370786\n",
      "   0.55847784]\n",
      " [ 0.40474829  0.47810172  0.30782151  0.30782151  0.30782151  0.47810172\n",
      "   0.30782151]]\n"
     ]
    }
   ],
   "source": [
    "# inverse document frequency and the importance of words/tokens\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer()\n",
    "print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test :) :( :)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data cleansing\n",
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    return text\n",
    "\n",
    "preprocessor(\"</a>This :) is :( a test :-)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "tokenizer('runners like running and thus they run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "    #return [porter.stem(word) for word in text.split()]\n",
    "    return pd.Series(text.split()).apply(porter.stem).tolist()\n",
    "tokenizer_porter('runners like running and thus they run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/grzegorz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runner', 'like', 'run', 'run', 'lot']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "[w for w in tokenizer_porter('a runner likes running and runs a lot')[-10:] if w not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df.loc[:25000, 'review'].values\n",
    "y_train = df.loc[:25000, 'sentiment'].values\n",
    "X_test = df.loc[25000:, 'review'].values\n",
    "y_test = df.loc[25000:, 'sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 80.8min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 3124.2min\n",
      "[Parallel(n_jobs=4)]: Done 240 out of 240 | elapsed: 3215.5min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tokenizers\n",
    "import pickle\n",
    "\n",
    "estimate = True\n",
    "\n",
    "if estimate:\n",
    "    param_grid = [{'vect__ngram_range': [(1,1)],\n",
    "                   'vect__stop_words': [stop, None],\n",
    "                   'vect__tokenizer': [tokenizers.tokenizer, \n",
    "                                       tokenizers.tokenizer_porter],\n",
    "                   'clf__penalty': ['l1', 'l2'],\n",
    "                   'clf__C': [1.0, 10.0, 100.0]},\n",
    "                  {'vect__ngram_range': [(1,1)],\n",
    "                   'vect__stop_words': [stop, None],\n",
    "                   'vect__tokenizer': [tokenizers.tokenizer, \n",
    "                                       tokenizers.tokenizer_porter],\n",
    "                   'vect__use_idf':[False],\n",
    "                   'vect__norm':[None],\n",
    "                   'clf__penalty': ['l1', 'l2'],\n",
    "                   'clf__C': [1.0, 10.0, 100.0]}]\n",
    "\n",
    "    lr_tfidf = Pipeline([('vect', TfidfVectorizer(strip_accents=None, \n",
    "                                                  lowercase=False, \n",
    "                                                  preprocessor=None)),\n",
    "                         ('clf', LogisticRegression(random_state=0))])\n",
    "    gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid, \n",
    "                               scoring='accuracy',\n",
    "                               cv=5, verbose=1,\n",
    "                               n_jobs=4)\n",
    "\n",
    "    gs_lr_tfidf.fit(X_train, y_train)\n",
    "    \n",
    "    with open('gs_lr_tfidf', 'wb') as f:\n",
    "        pickle.dump(gs_lr_tfidf, f, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(\"gs_lr_tfidf\", \"rb\") as f:\n",
    "        gs_lr_tfidf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8938517240212499"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(gs_lr_tfidf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_tfidf.predict(['I like this movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 10.0,\n",
       " 'clf__penalty': 'l2',\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__stop_words': None,\n",
       " 'vect__tokenizer': <function tokenizers.tokenizer>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_tfidf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88932902973395933"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_tfidf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8938517240212499"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_tfidf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with bigger data – online algorithms and out-of-core learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tralalala', ':)']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    return tokenized\n",
    "\n",
    "tokenizer('tralalala:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stream_docs(path):\n",
    "    with open(path, 'r', encoding='utf8') as csv:\n",
    "        next(csv) # skip header\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\"Gorgeous Annie Belle in her prime stars in this adventure/sex movie. She wears her hair in a buzz cut that is bleached platinum. She and her boyfriend are visiting some tropical Asian paradise. They have decided to keep an \"\"open\"\" sexual relationship, which is played out on their journey to find a secret society/tribe where the people live one year and then are reborn in some kind of ceremony. The scenery is gorgeous, deep vast green gorges and jungles are explored. The imagery is very similar to that of the movie \"\"Black Emanuelle\"\". It is rich and colorful. Recommended!\"', 1)\n",
      "('\"How is bear´s paw, elephant´s trunk or monkey´s brain for dinner? Let Tsui Hark tell you in this wonderful and lighthearted comedy about the art of cooking the traditional(?) Chinese way.<br /><br />This movie shares the common structure of an American sports movie, but instead of focusing on baseball it centers around cooking which makes it all the more interesting. I even think Leslie Cheung´s character look a lot like Charlie Sheen in Major League...<br /><br />This movie also contains a bit of Zhao Wen Zhao vs Xiong Xin Xin fighting (love seeing more of that after The Blade) and a quite funny in-joke concerning a Leon Lai pop song...<br /><br />Perhaps not the ideal movie for the strict vegetarian though.\"', 1)\n"
     ]
    }
   ],
   "source": [
    "sd = stream_docs(path='./downloads/aclImdb/movie_data.csv')\n",
    "print(next(sd))\n",
    "print(next(sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.to_csv('./downloads/aclImdb/movie_data_unsorted.csv', index=False, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore', \n",
    "                         n_features=2**21, \n",
    "                         preprocessor=None,\n",
    "                         tokenizer=tokenizer)\n",
    "clf = SGDClassifier(loss='log', n_iter=1)\n",
    "doc_stream = stream_docs(path='./downloads/aclImdb/movie_data_unsorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:30\n"
     ]
    }
   ],
   "source": [
    "import pyprind\n",
    "\n",
    "pbar = pyprind.ProgBar(45)\n",
    "classes = np.array([0, 1])\n",
    "\n",
    "for _ in range(45):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size=1000)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.873\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = get_minibatch(doc_stream, size=5000)\n",
    "X_test = vect.transform(X_test)\n",
    "print('Accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = clf.partial_fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08967493,  0.91032507]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(vect.transform(['I love it']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 9: Serializing objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "dest = os.path.join('movieclassifier', 'pkl_objects')\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "#pickle.dump(stop, open(os.path.join(dest, 'stopwords.pkl'),'wb'), protocol=4)\n",
    "pickle.dump(clf, open(os.path.join(dest, 'classifier.pkl'), 'wb'), protocol=4)\n",
    "#pickle.dump(gs_lr_tfidf, open(os.path.join(dest, 'classifier_large.pkl'), 'wb'), protocol=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
